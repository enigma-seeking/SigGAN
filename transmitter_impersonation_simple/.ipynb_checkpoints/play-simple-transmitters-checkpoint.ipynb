{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from WirelessSystem.system import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/cores/miniconda3/envs/tf_gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/cores/miniconda3/envs/tf_gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/cores/miniconda3/envs/tf_gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/cores/miniconda3/envs/tf_gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from SigGAN.train import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(sig_u):\n",
    "    pwr = np.sqrt(np.mean(np.sum(sig_u**2,axis = -1),axis = -1))\n",
    "    sig_u = sig_u/pwr[:,None,None]\n",
    "    print(sig_u.shape)\n",
    "    return sig_u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle(vec1,vec2,seed = 0):\n",
    "    np.random.seed(0)\n",
    "    shfl_indx = np.arange(vec1.shape[0])\n",
    "    np.random.shuffle(shfl_indx)\n",
    "    shfl_indx = shfl_indx.astype('int')\n",
    "    vec1 = vec1[shfl_indx]\n",
    "    vec2 = np.copy(vec2[shfl_indx])\n",
    "    return vec1,vec2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(vec,n_train,n_valid,n_test):\n",
    "    vec_train = vec[0:n_train]\n",
    "    vec_valid = vec[n_train:n_train+n_valid]\n",
    "    vec_test = vec[n_train+n_valid:]\n",
    "    return vec_train,vec_valid,vec_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_symbols = 256 // 2\n",
    "n_authorized = 10\n",
    "n_unauthorized = 10\n",
    "sess_name = 'test_transmitters_snr'\n",
    "snr=0\n",
    "suffix='_t_%d_snr_%d'%(n_authorized,snr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_system = RFSystem(n_authorized = n_authorized, n_unauthorized = n_unauthorized, snr = snr, sess_name = sess_name, suffix=suffix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rf_system = RFSystem(sess_dir='test_binary_reward_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_auth_, txid_auth = rf_system.get_n_received_symbol_blocks(5000, n_symbols, authorized = 0)\n",
    "sig_unauth_, txid_unauth = rf_system.get_n_received_symbol_blocks(5000, n_symbols, authorized = 1)\n",
    "sig_impersonate_, _ = rf_system.get_n_received_symbol_blocks(10, n_symbols, authorized = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_auth=sig_auth_\n",
    "sig_unauth=sig_unauth_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_impersonate_ad_, _ = rf_system.get_n_received_symbol_blocks(5000, n_symbols, authorized = 2)\n",
    "sig_impersonate_ad=sig_impersonate_ad_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_impersonate=sig_impersonate_.reshape((-1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper parameters\n",
    "B = 64 # batch size\n",
    "T = 256 # Max length of sentence\n",
    "g_H = 100 # Generator LSTM hidden size\n",
    "g_lr = 1e-3\n",
    "d_dropout = 0.5 # dropout ratio\n",
    "d_lr = 1e-3\n",
    "\n",
    "n_sample=1 # Number of Monte Calro Search\n",
    "generate_samples = 2000 # Number of generated sentences\n",
    "\n",
    "# Pretraining parameters\n",
    "g_pre_lr = 1e-3\n",
    "d_pre_lr = 1e-3\n",
    "g_pre_epochs= 60\n",
    "d_pre_epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/cores/miniconda3/envs/tf_gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/cores/miniconda3/envs/tf_gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/cores/miniconda3/envs/tf_gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/cores/google-drive-samurdhi/Research/transmitter_impersonation_simple/SigGAN/models.py:104: The name tf.train.exponential_decay is deprecated. Please use tf.compat.v1.train.exponential_decay instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/cores/google-drive-samurdhi/Research/transmitter_impersonation_simple/SigGAN/models.py:106: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /home/cores/miniconda3/envs/tf_gpu/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/cores/google-drive-samurdhi/Research/transmitter_impersonation_simple/SigGAN/models.py:124: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/cores/miniconda3/envs/tf_gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/cores/miniconda3/envs/tf_gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/cores/miniconda3/envs/tf_gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/cores/miniconda3/envs/tf_gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/cores/miniconda3/envs/tf_gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(rf_system, B, T, n_authorized, g_H, d_dropout, g_lr=g_lr, d_lr=d_lr, n_sample=n_sample, generate_samples=generate_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_rd = np.concatenate([sig_auth,sig_impersonate_ad])\n",
    "txid_rd = np.concatenate([txid_auth,np.ones((sig_impersonate_ad.shape[0],))*n_authorized])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sig_rd = np.concatenate([sig_auth,sig_unauth])\n",
    "# txid_rd = np.concatenate([txid_auth,np.ones((sig_unauth.shape[0],))*n_authorized])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_rd, txid_rd = shuffle(sig_rd, txid_rd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "txid_disc = txid_rd == n_authorized\n",
    "txid_disc = np.invert(txid_disc)\n",
    "txid_disc = txid_disc.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n",
      "[ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10.]\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(txid_disc))\n",
    "print(np.unique(txid_rd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_frac = 0.1\n",
    "valid_frac  = 0.2\n",
    "\n",
    "n_samples  = sig_rd.shape[0]\n",
    "\n",
    "n_test = int(test_frac*n_samples)\n",
    "n_valid = int(valid_frac*n_samples)\n",
    "n_train = n_samples - n_test - n_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_rd_train,sig_rd_valid,sig_rd_test=split(sig_rd,n_train,n_valid,n_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_train,out_valid,out_test=split(txid_disc,n_train,n_valid,n_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainer.load_pre_train_d(rf_system.full_sess_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 256, 2)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 256, 2, 1)    0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "1_conv1 (Conv2D)                (None, 256, 2, 16)   32          reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "1_conv2 (Conv2D)                (None, 256, 2, 16)   1552        1_conv1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "1_bn (BatchNormalization)       (None, 256, 2, 16)   64          1_conv2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "1_act1 (Activation)             (None, 256, 2, 16)   0           1_bn[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "1_conv3 (Conv2D)                (None, 256, 2, 16)   1552        1_act1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "1_bn2 (BatchNormalization)      (None, 256, 2, 16)   64          1_conv3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "1_add (Add)                     (None, 256, 2, 16)   0           1_bn2[0][0]                      \n",
      "                                                                 1_conv1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "1_act2 (Activation)             (None, 256, 2, 16)   0           1_add[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "3_0_conv1 (Conv2D)              (None, 256, 2, 32)   544         1_act2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "3_0_conv2 (Conv2D)              (None, 256, 2, 32)   6176        3_0_conv1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "3_0_bn (BatchNormalization)     (None, 256, 2, 32)   128         3_0_conv2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "3_0_act1 (Activation)           (None, 256, 2, 32)   0           3_0_bn[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "3_0_conv3 (Conv2D)              (None, 256, 2, 32)   6176        3_0_act1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "3_0_bn2 (BatchNormalization)    (None, 256, 2, 32)   128         3_0_conv3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "3_0_add (Add)                   (None, 256, 2, 32)   0           3_0_bn2[0][0]                    \n",
      "                                                                 3_0_conv1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "3_0_act2 (Activation)           (None, 256, 2, 32)   0           3_0_add[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 128, 2, 32)   0           3_0_act2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 128, 2, 16)   528         max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 4096)         0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 20)           81940       flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 20)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sftmx_0 (Dense)                 (None, 1)            21          dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 98,905\n",
      "Trainable params: 98,713\n",
      "Non-trainable params: 192\n",
      "__________________________________________________________________________________________________\n",
      "Discriminator pre-training\n",
      "Train on 7000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      "7000/7000 [==============================] - 3s 436us/step - loss: 0.5859 - val_loss: 0.6532\n",
      "Epoch 2/100\n",
      "7000/7000 [==============================] - 2s 251us/step - loss: 0.5840 - val_loss: 0.6625\n",
      "Epoch 3/100\n",
      "7000/7000 [==============================] - 2s 246us/step - loss: 0.5734 - val_loss: 0.6526\n",
      "Epoch 4/100\n",
      "7000/7000 [==============================] - 2s 250us/step - loss: 0.5856 - val_loss: 0.6540\n",
      "Epoch 5/100\n",
      "7000/7000 [==============================] - 2s 253us/step - loss: 0.5720 - val_loss: 0.6514\n",
      "Epoch 6/100\n",
      "7000/7000 [==============================] - 2s 263us/step - loss: 0.5805 - val_loss: 0.6509\n",
      "Epoch 7/100\n",
      "7000/7000 [==============================] - 2s 260us/step - loss: 0.5716 - val_loss: 0.6515\n",
      "Epoch 8/100\n",
      "7000/7000 [==============================] - 2s 251us/step - loss: 0.5733 - val_loss: 0.6510\n",
      "Epoch 9/100\n",
      "7000/7000 [==============================] - 2s 254us/step - loss: 0.5690 - val_loss: 0.6530\n",
      "Epoch 10/100\n",
      "7000/7000 [==============================] - 2s 260us/step - loss: 0.5693 - val_loss: 0.6494\n",
      "Epoch 11/100\n",
      "7000/7000 [==============================] - 2s 264us/step - loss: 0.5711 - val_loss: 0.6507\n",
      "Epoch 12/100\n",
      "7000/7000 [==============================] - 2s 258us/step - loss: 0.5585 - val_loss: 0.6566\n",
      "Epoch 13/100\n",
      "7000/7000 [==============================] - 2s 255us/step - loss: 0.5638 - val_loss: 0.6501\n",
      "Epoch 14/100\n",
      "7000/7000 [==============================] - 2s 268us/step - loss: 0.5638 - val_loss: 0.6523\n",
      "Epoch 15/100\n",
      "7000/7000 [==============================] - 2s 259us/step - loss: 0.5609 - val_loss: 0.6507\n",
      "Epoch 16/100\n",
      "7000/7000 [==============================] - 2s 255us/step - loss: 0.5586 - val_loss: 0.6515\n",
      "Epoch 17/100\n",
      "7000/7000 [==============================] - 2s 268us/step - loss: 0.5553 - val_loss: 0.6516\n",
      "Epoch 18/100\n",
      "7000/7000 [==============================] - 2s 254us/step - loss: 0.5589 - val_loss: 0.6533\n",
      "Epoch 19/100\n",
      "7000/7000 [==============================] - 2s 251us/step - loss: 0.5465 - val_loss: 0.6518\n",
      "Epoch 20/100\n",
      "7000/7000 [==============================] - 2s 270us/step - loss: 0.5533 - val_loss: 0.6532\n",
      "Epoch 21/100\n",
      "7000/7000 [==============================] - 2s 255us/step - loss: 0.5523 - val_loss: 0.6501\n",
      "Epoch 22/100\n",
      "7000/7000 [==============================] - 2s 250us/step - loss: 0.5519 - val_loss: 0.6521\n",
      "Epoch 23/100\n",
      "7000/7000 [==============================] - 2s 267us/step - loss: 0.5499 - val_loss: 0.6495\n",
      "Epoch 24/100\n",
      "7000/7000 [==============================] - 2s 256us/step - loss: 0.5464 - val_loss: 0.6515\n",
      "Epoch 25/100\n",
      "7000/7000 [==============================] - 2s 256us/step - loss: 0.5429 - val_loss: 0.6543\n",
      "Epoch 26/100\n",
      "7000/7000 [==============================] - 2s 268us/step - loss: 0.5427 - val_loss: 0.6493\n",
      "Epoch 27/100\n",
      "7000/7000 [==============================] - 2s 263us/step - loss: 0.5404 - val_loss: 0.6526\n",
      "Epoch 28/100\n",
      "7000/7000 [==============================] - 2s 259us/step - loss: 0.5410 - val_loss: 0.6506\n",
      "Epoch 29/100\n",
      "7000/7000 [==============================] - 2s 257us/step - loss: 0.5411 - val_loss: 0.6480\n",
      "Epoch 30/100\n",
      "7000/7000 [==============================] - 2s 257us/step - loss: 0.5401 - val_loss: 0.6497\n",
      "Epoch 31/100\n",
      "7000/7000 [==============================] - 2s 253us/step - loss: 0.5375 - val_loss: 0.6529\n",
      "Epoch 32/100\n",
      "7000/7000 [==============================] - 2s 269us/step - loss: 0.5382 - val_loss: 0.6515\n",
      "Epoch 33/100\n",
      "7000/7000 [==============================] - 2s 251us/step - loss: 0.5355 - val_loss: 0.6508\n",
      "Epoch 34/100\n",
      "7000/7000 [==============================] - 2s 253us/step - loss: 0.5336 - val_loss: 0.6460\n",
      "Epoch 35/100\n",
      "7000/7000 [==============================] - 2s 256us/step - loss: 0.5274 - val_loss: 0.6494\n",
      "Epoch 36/100\n",
      "7000/7000 [==============================] - 2s 256us/step - loss: 0.5312 - val_loss: 0.6475\n",
      "Epoch 37/100\n",
      "7000/7000 [==============================] - 2s 265us/step - loss: 0.5321 - val_loss: 0.6483\n",
      "Epoch 38/100\n",
      "7000/7000 [==============================] - 2s 255us/step - loss: 0.5301 - val_loss: 0.6501\n",
      "Epoch 39/100\n",
      "7000/7000 [==============================] - 2s 261us/step - loss: 0.5269 - val_loss: 0.6533\n",
      "Epoch 40/100\n",
      "7000/7000 [==============================] - 2s 252us/step - loss: 0.5282 - val_loss: 0.6473\n",
      "Epoch 41/100\n",
      "7000/7000 [==============================] - 2s 256us/step - loss: 0.5241 - val_loss: 0.6515\n",
      "Epoch 42/100\n",
      "7000/7000 [==============================] - 2s 262us/step - loss: 0.5233 - val_loss: 0.6471\n",
      "Epoch 43/100\n",
      "7000/7000 [==============================] - 2s 261us/step - loss: 0.5176 - val_loss: 0.6504\n",
      "Epoch 44/100\n",
      "7000/7000 [==============================] - 2s 254us/step - loss: 0.5136 - val_loss: 0.6543\n",
      "Epoch 45/100\n",
      "7000/7000 [==============================] - 2s 267us/step - loss: 0.5199 - val_loss: 0.6485\n",
      "Epoch 46/100\n",
      "7000/7000 [==============================] - 2s 254us/step - loss: 0.5132 - val_loss: 0.6496\n",
      "Epoch 47/100\n",
      "7000/7000 [==============================] - 2s 256us/step - loss: 0.5198 - val_loss: 0.6477\n",
      "Epoch 48/100\n",
      "7000/7000 [==============================] - 2s 270us/step - loss: 0.5116 - val_loss: 0.6480\n",
      "Epoch 49/100\n",
      "7000/7000 [==============================] - 2s 254us/step - loss: 0.5123 - val_loss: 0.6491\n",
      "Epoch 50/100\n",
      "7000/7000 [==============================] - 2s 254us/step - loss: 0.5052 - val_loss: 0.6489\n",
      "Epoch 51/100\n",
      "7000/7000 [==============================] - 2s 268us/step - loss: 0.5176 - val_loss: 0.6501\n",
      "Epoch 52/100\n",
      "7000/7000 [==============================] - 2s 256us/step - loss: 0.5100 - val_loss: 0.6531\n",
      "Epoch 53/100\n",
      "7000/7000 [==============================] - 2s 254us/step - loss: 0.5075 - val_loss: 0.6494\n",
      "Epoch 54/100\n",
      "7000/7000 [==============================] - 2s 269us/step - loss: 0.5068 - val_loss: 0.6488\n",
      "Epoch 55/100\n",
      "7000/7000 [==============================] - 2s 254us/step - loss: 0.5072 - val_loss: 0.6514\n",
      "Epoch 56/100\n",
      "7000/7000 [==============================] - 2s 255us/step - loss: 0.5034 - val_loss: 0.6506\n",
      "Epoch 57/100\n",
      "7000/7000 [==============================] - 2s 268us/step - loss: 0.5002 - val_loss: 0.6500\n",
      "Epoch 58/100\n",
      "7000/7000 [==============================] - 2s 256us/step - loss: 0.5021 - val_loss: 0.6513\n",
      "Epoch 59/100\n",
      "7000/7000 [==============================] - 2s 258us/step - loss: 0.4993 - val_loss: 0.6587\n",
      "Epoch 60/100\n",
      "7000/7000 [==============================] - 2s 268us/step - loss: 0.4988 - val_loss: 0.6563\n",
      "Epoch 61/100\n",
      "7000/7000 [==============================] - 2s 254us/step - loss: 0.5005 - val_loss: 0.6489\n",
      "Epoch 62/100\n",
      "7000/7000 [==============================] - 2s 257us/step - loss: 0.4995 - val_loss: 0.6518\n",
      "Epoch 63/100\n",
      "7000/7000 [==============================] - 2s 263us/step - loss: 0.4963 - val_loss: 0.6520\n",
      "Epoch 64/100\n",
      "7000/7000 [==============================] - 2s 253us/step - loss: 0.4886 - val_loss: 0.6608\n",
      "Epoch 65/100\n",
      "7000/7000 [==============================] - 2s 265us/step - loss: 0.4955 - val_loss: 0.6544\n",
      "Epoch 66/100\n",
      "7000/7000 [==============================] - 2s 261us/step - loss: 0.4909 - val_loss: 0.6509\n",
      "Epoch 67/100\n",
      "7000/7000 [==============================] - 2s 249us/step - loss: 0.4880 - val_loss: 0.6503\n",
      "Epoch 68/100\n",
      "7000/7000 [==============================] - 2s 263us/step - loss: 0.4898 - val_loss: 0.6532\n",
      "Epoch 69/100\n",
      "7000/7000 [==============================] - 2s 245us/step - loss: 0.4881 - val_loss: 0.6495\n",
      "Epoch 70/100\n",
      "7000/7000 [==============================] - 2s 254us/step - loss: 0.4850 - val_loss: 0.6541\n",
      "Epoch 71/100\n",
      "7000/7000 [==============================] - 2s 268us/step - loss: 0.4885 - val_loss: 0.6514\n",
      "Epoch 72/100\n",
      "7000/7000 [==============================] - 2s 256us/step - loss: 0.4858 - val_loss: 0.6592\n",
      "Epoch 73/100\n",
      "7000/7000 [==============================] - 2s 252us/step - loss: 0.4844 - val_loss: 0.6510\n",
      "Epoch 74/100\n",
      "7000/7000 [==============================] - 2s 257us/step - loss: 0.4804 - val_loss: 0.6537\n",
      "Epoch 75/100\n",
      "7000/7000 [==============================] - 2s 248us/step - loss: 0.4813 - val_loss: 0.6566\n",
      "Epoch 76/100\n",
      "7000/7000 [==============================] - 2s 258us/step - loss: 0.4750 - val_loss: 0.6507\n",
      "Epoch 77/100\n",
      "7000/7000 [==============================] - 2s 267us/step - loss: 0.4773 - val_loss: 0.6531\n",
      "Epoch 78/100\n",
      "7000/7000 [==============================] - 2s 249us/step - loss: 0.4729 - val_loss: 0.6589\n",
      "Epoch 79/100\n",
      "7000/7000 [==============================] - 2s 257us/step - loss: 0.4811 - val_loss: 0.6488\n",
      "Epoch 80/100\n",
      "7000/7000 [==============================] - 2s 264us/step - loss: 0.4830 - val_loss: 0.6546\n",
      "Epoch 81/100\n",
      "7000/7000 [==============================] - 2s 255us/step - loss: 0.4737 - val_loss: 0.6538\n",
      "Epoch 82/100\n",
      "7000/7000 [==============================] - 2s 259us/step - loss: 0.4710 - val_loss: 0.6565\n",
      "Epoch 83/100\n",
      "7000/7000 [==============================] - 2s 263us/step - loss: 0.4768 - val_loss: 0.6532\n",
      "Epoch 84/100\n",
      "7000/7000 [==============================] - 2s 256us/step - loss: 0.4766 - val_loss: 0.6587\n",
      "Epoch 85/100\n",
      "7000/7000 [==============================] - 2s 264us/step - loss: 0.4711 - val_loss: 0.6529\n",
      "Epoch 86/100\n",
      "7000/7000 [==============================] - 2s 260us/step - loss: 0.4734 - val_loss: 0.6551\n",
      "Epoch 87/100\n",
      "7000/7000 [==============================] - 2s 255us/step - loss: 0.4701 - val_loss: 0.6555\n",
      "Epoch 88/100\n",
      "7000/7000 [==============================] - 2s 265us/step - loss: 0.4711 - val_loss: 0.6517\n",
      "Epoch 89/100\n",
      "7000/7000 [==============================] - 2s 258us/step - loss: 0.4653 - val_loss: 0.6517\n",
      "Epoch 90/100\n",
      "7000/7000 [==============================] - 2s 256us/step - loss: 0.4695 - val_loss: 0.6520\n",
      "Epoch 91/100\n",
      "7000/7000 [==============================] - 2s 265us/step - loss: 0.4643 - val_loss: 0.6503\n",
      "Epoch 92/100\n",
      "7000/7000 [==============================] - 2s 259us/step - loss: 0.4685 - val_loss: 0.6519\n",
      "Epoch 93/100\n",
      "7000/7000 [==============================] - 2s 253us/step - loss: 0.4617 - val_loss: 0.6538\n",
      "Epoch 94/100\n",
      "7000/7000 [==============================] - 2s 265us/step - loss: 0.4619 - val_loss: 0.6554\n",
      "Epoch 95/100\n",
      "7000/7000 [==============================] - 2s 250us/step - loss: 0.4599 - val_loss: 0.6533\n",
      "Epoch 96/100\n",
      "7000/7000 [==============================] - 2s 250us/step - loss: 0.4562 - val_loss: 0.6548\n",
      "Epoch 97/100\n",
      "7000/7000 [==============================] - 2s 262us/step - loss: 0.4583 - val_loss: 0.6587\n",
      "Epoch 98/100\n",
      "7000/7000 [==============================] - 2s 248us/step - loss: 0.4561 - val_loss: 0.6578\n",
      "Epoch 99/100\n",
      "7000/7000 [==============================] - 2s 251us/step - loss: 0.4599 - val_loss: 0.6592\n",
      "Epoch 100/100\n",
      "7000/7000 [==============================] - 2s 267us/step - loss: 0.4534 - val_loss: 0.6572\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.pre_train_discriminator(d_epochs=100, d_pre_sig_train=sig_rd_train, d_pre_out_train=out_train, d_pre_sig_valid=sig_rd_valid, d_pre_out_valid=out_valid, lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_pre_train_d(rf_system.full_sess_dir, suffix=suffix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8798571428571429\n"
     ]
    }
   ],
   "source": [
    "print(trainer.test_discriminator(sig_rd_train, out_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.815\n"
     ]
    }
   ],
   "source": [
    "print(trainer.test_discriminator(sig_rd_valid, out_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.815\n"
     ]
    }
   ],
   "source": [
    "print(trainer.test_discriminator(sig_rd_test, out_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9482\n"
     ]
    }
   ],
   "source": [
    "print(trainer.test_discriminator(sig_impersonate_ad, np.zeros((sig_impersonate_ad.shape[0],))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.77877665"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(trainer.predict_discriminator(sig_auth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22131768"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(trainer.predict_discriminator(sig_impersonate_ad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples_im  = sig_impersonate.shape[0]\n",
    "\n",
    "n_test_im = int(test_frac*n_samples_im)\n",
    "n_valid_im = int(valid_frac*n_samples_im)\n",
    "n_train_im = n_samples_im - n_test_im - n_valid_im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_im_train,sig_im_valid,sig_im_test=split(sig_impersonate,n_train_im,n_valid_im,n_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_im_train_re = sig_im_train.reshape((-1, 1, 2))\n",
    "sig_im_train_re_t = sig_im_train.reshape((-1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_im_valid_re = sig_im_valid.reshape((-1, 1, 2))\n",
    "sig_im_valid_re_t = sig_im_valid.reshape((-1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_im_test_re = sig_im_test.reshape((-1, 1,  2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator pre-training\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              (None, None, 2)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "LSTM (LSTM)                     (None, 100)          41200       Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "DenseMean (Dense)               (None, 2)            202         LSTM[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "DenseVariance (Dense)           (None, 2)            202         LSTM[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "sampling_layer (Lambda)         (None, 2)            0           DenseMean[0][0]                  \n",
      "                                                                 DenseVariance[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 41,604\n",
      "Trainable params: 41,604\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 1792 samples, validate on 512 samples\n",
      "Epoch 1/100\n",
      "1792/1792 [==============================] - 3s 2ms/step - loss: 1.8717 - val_loss: 1.5807\n",
      "Epoch 2/100\n",
      "1792/1792 [==============================] - 0s 164us/step - loss: 1.2210 - val_loss: 0.8871\n",
      "Epoch 3/100\n",
      "1792/1792 [==============================] - 0s 182us/step - loss: 0.5609 - val_loss: 0.3026\n",
      "Epoch 4/100\n",
      "1792/1792 [==============================] - 0s 168us/step - loss: 0.2389 - val_loss: 0.1883\n",
      "Epoch 5/100\n",
      "1792/1792 [==============================] - 0s 155us/step - loss: 0.1621 - val_loss: 0.1234\n",
      "Epoch 6/100\n",
      "1792/1792 [==============================] - 0s 168us/step - loss: 0.1102 - val_loss: 0.0919\n",
      "Epoch 7/100\n",
      "1792/1792 [==============================] - 0s 162us/step - loss: 0.0737 - val_loss: 0.0617\n",
      "Epoch 8/100\n",
      "1792/1792 [==============================] - 0s 166us/step - loss: 0.0543 - val_loss: 0.0467\n",
      "Epoch 9/100\n",
      "1792/1792 [==============================] - 0s 161us/step - loss: 0.0409 - val_loss: 0.0370\n",
      "Epoch 10/100\n",
      "1792/1792 [==============================] - 0s 162us/step - loss: 0.0309 - val_loss: 0.0273\n",
      "Epoch 11/100\n",
      "1792/1792 [==============================] - 0s 168us/step - loss: 0.0248 - val_loss: 0.0213\n",
      "Epoch 12/100\n",
      "1792/1792 [==============================] - 0s 167us/step - loss: 0.0192 - val_loss: 0.0164\n",
      "Epoch 13/100\n",
      "1792/1792 [==============================] - 0s 165us/step - loss: 0.0150 - val_loss: 0.0136\n",
      "Epoch 14/100\n",
      "1792/1792 [==============================] - 0s 161us/step - loss: 0.0117 - val_loss: 0.0113\n",
      "Epoch 15/100\n",
      "1792/1792 [==============================] - 0s 161us/step - loss: 0.0099 - val_loss: 0.0104\n",
      "Epoch 16/100\n",
      "1792/1792 [==============================] - 0s 167us/step - loss: 0.0086 - val_loss: 0.0077\n",
      "Epoch 17/100\n",
      "1792/1792 [==============================] - 0s 166us/step - loss: 0.0075 - val_loss: 0.0067\n",
      "Epoch 18/100\n",
      "1792/1792 [==============================] - 0s 170us/step - loss: 0.0061 - val_loss: 0.0055\n",
      "Epoch 19/100\n",
      "1792/1792 [==============================] - 0s 170us/step - loss: 0.0051 - val_loss: 0.0050\n",
      "Epoch 20/100\n",
      "1792/1792 [==============================] - 0s 168us/step - loss: 0.0046 - val_loss: 0.0040\n",
      "Epoch 21/100\n",
      "1792/1792 [==============================] - 0s 160us/step - loss: 0.0039 - val_loss: 0.0045\n",
      "Epoch 22/100\n",
      "1792/1792 [==============================] - 0s 157us/step - loss: 0.0036 - val_loss: 0.0033\n",
      "Epoch 23/100\n",
      "1792/1792 [==============================] - 0s 172us/step - loss: 0.0033 - val_loss: 0.0029\n",
      "Epoch 24/100\n",
      "1792/1792 [==============================] - 0s 158us/step - loss: 0.0027 - val_loss: 0.0026\n",
      "Epoch 25/100\n",
      "1792/1792 [==============================] - 0s 163us/step - loss: 0.0025 - val_loss: 0.0024\n",
      "Epoch 26/100\n",
      "1792/1792 [==============================] - 0s 164us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 27/100\n",
      "1792/1792 [==============================] - 0s 171us/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 28/100\n",
      "1792/1792 [==============================] - 0s 170us/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 29/100\n",
      "1792/1792 [==============================] - 0s 165us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 30/100\n",
      "1792/1792 [==============================] - 0s 171us/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 31/100\n",
      "1792/1792 [==============================] - 0s 161us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 32/100\n",
      "1792/1792 [==============================] - 0s 180us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 33/100\n",
      "1792/1792 [==============================] - 0s 162us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 34/100\n",
      "1792/1792 [==============================] - 0s 173us/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 35/100\n",
      "1792/1792 [==============================] - 0s 162us/step - loss: 0.0010 - val_loss: 8.5351e-04\n",
      "Epoch 36/100\n",
      "1792/1792 [==============================] - 0s 158us/step - loss: 9.6739e-04 - val_loss: 9.0337e-04\n",
      "Epoch 37/100\n",
      "1792/1792 [==============================] - 0s 156us/step - loss: 8.7084e-04 - val_loss: 8.5258e-04\n",
      "Epoch 38/100\n",
      "1792/1792 [==============================] - 0s 163us/step - loss: 8.3472e-04 - val_loss: 8.3492e-04\n",
      "Epoch 39/100\n",
      "1792/1792 [==============================] - 0s 160us/step - loss: 8.1868e-04 - val_loss: 6.9246e-04\n",
      "Epoch 40/100\n",
      "1792/1792 [==============================] - 0s 155us/step - loss: 7.1056e-04 - val_loss: 6.7533e-04\n",
      "Epoch 41/100\n",
      "1792/1792 [==============================] - 0s 158us/step - loss: 6.5865e-04 - val_loss: 6.4272e-04\n",
      "Epoch 42/100\n",
      "1792/1792 [==============================] - 0s 167us/step - loss: 6.5014e-04 - val_loss: 6.1179e-04\n",
      "Epoch 43/100\n",
      "1792/1792 [==============================] - 0s 162us/step - loss: 5.5631e-04 - val_loss: 5.3521e-04\n",
      "Epoch 44/100\n",
      "1792/1792 [==============================] - 0s 159us/step - loss: 5.2670e-04 - val_loss: 5.9851e-04\n",
      "Epoch 45/100\n",
      "1792/1792 [==============================] - 0s 161us/step - loss: 4.7076e-04 - val_loss: 5.3818e-04\n",
      "Epoch 46/100\n",
      "1792/1792 [==============================] - 0s 168us/step - loss: 4.8032e-04 - val_loss: 5.2438e-04\n",
      "Epoch 47/100\n",
      "1792/1792 [==============================] - 0s 159us/step - loss: 4.7133e-04 - val_loss: 5.2071e-04\n",
      "Epoch 48/100\n",
      "1792/1792 [==============================] - 0s 161us/step - loss: 4.3518e-04 - val_loss: 5.2002e-04\n",
      "Epoch 49/100\n",
      "1792/1792 [==============================] - 0s 169us/step - loss: 4.1354e-04 - val_loss: 4.0705e-04\n",
      "Epoch 50/100\n",
      "1792/1792 [==============================] - 0s 155us/step - loss: 3.7191e-04 - val_loss: 3.8969e-04\n",
      "Epoch 51/100\n",
      "1792/1792 [==============================] - 0s 166us/step - loss: 3.5556e-04 - val_loss: 3.4803e-04\n",
      "Epoch 52/100\n",
      "1792/1792 [==============================] - 0s 159us/step - loss: 3.4428e-04 - val_loss: 3.4350e-04\n",
      "Epoch 53/100\n",
      "1792/1792 [==============================] - 0s 168us/step - loss: 3.3529e-04 - val_loss: 3.7730e-04\n",
      "Epoch 54/100\n",
      "1792/1792 [==============================] - 0s 161us/step - loss: 3.1929e-04 - val_loss: 2.9662e-04\n",
      "Epoch 55/100\n",
      "1792/1792 [==============================] - 0s 162us/step - loss: 2.9519e-04 - val_loss: 2.6851e-04\n",
      "Epoch 56/100\n",
      "1792/1792 [==============================] - 0s 170us/step - loss: 3.0160e-04 - val_loss: 2.8575e-04\n",
      "Epoch 57/100\n",
      "1792/1792 [==============================] - 0s 157us/step - loss: 2.8942e-04 - val_loss: 2.5726e-04\n",
      "Epoch 58/100\n",
      "1792/1792 [==============================] - 0s 158us/step - loss: 2.4511e-04 - val_loss: 2.8689e-04\n",
      "Epoch 59/100\n",
      "1792/1792 [==============================] - 0s 167us/step - loss: 2.5181e-04 - val_loss: 2.3094e-04\n",
      "Epoch 60/100\n",
      "1792/1792 [==============================] - 0s 161us/step - loss: 2.3480e-04 - val_loss: 2.3971e-04\n",
      "Epoch 61/100\n",
      "1792/1792 [==============================] - 0s 171us/step - loss: 2.2397e-04 - val_loss: 2.2166e-04\n",
      "Epoch 62/100\n",
      "1792/1792 [==============================] - 0s 160us/step - loss: 2.0396e-04 - val_loss: 2.0588e-04\n",
      "Epoch 63/100\n",
      "1792/1792 [==============================] - 0s 161us/step - loss: 2.1412e-04 - val_loss: 1.9711e-04\n",
      "Epoch 64/100\n",
      "1792/1792 [==============================] - 0s 167us/step - loss: 1.8734e-04 - val_loss: 1.9302e-04\n",
      "Epoch 65/100\n",
      "1792/1792 [==============================] - 0s 162us/step - loss: 1.9343e-04 - val_loss: 1.9023e-04\n",
      "Epoch 66/100\n",
      "1792/1792 [==============================] - 0s 168us/step - loss: 1.9050e-04 - val_loss: 1.8350e-04\n",
      "Epoch 67/100\n",
      "1792/1792 [==============================] - 0s 162us/step - loss: 1.6770e-04 - val_loss: 1.7914e-04\n",
      "Epoch 68/100\n",
      "1792/1792 [==============================] - 0s 167us/step - loss: 1.7003e-04 - val_loss: 1.7852e-04\n",
      "Epoch 69/100\n",
      "1792/1792 [==============================] - 0s 162us/step - loss: 1.5931e-04 - val_loss: 1.5863e-04\n",
      "Epoch 70/100\n",
      "1792/1792 [==============================] - 0s 160us/step - loss: 1.5074e-04 - val_loss: 1.6473e-04\n",
      "Epoch 71/100\n",
      "1792/1792 [==============================] - 0s 161us/step - loss: 1.5261e-04 - val_loss: 1.3862e-04\n",
      "Epoch 72/100\n",
      "1792/1792 [==============================] - 0s 164us/step - loss: 1.3953e-04 - val_loss: 1.3009e-04\n",
      "Epoch 73/100\n",
      "1792/1792 [==============================] - 0s 160us/step - loss: 1.2740e-04 - val_loss: 1.3344e-04\n",
      "Epoch 74/100\n",
      "1792/1792 [==============================] - 0s 159us/step - loss: 1.2849e-04 - val_loss: 1.3462e-04\n",
      "Epoch 75/100\n",
      "1792/1792 [==============================] - 0s 164us/step - loss: 1.2328e-04 - val_loss: 1.2027e-04\n",
      "Epoch 76/100\n",
      "1792/1792 [==============================] - 0s 163us/step - loss: 1.1909e-04 - val_loss: 1.1347e-04\n",
      "Epoch 77/100\n",
      "1792/1792 [==============================] - 0s 159us/step - loss: 1.1371e-04 - val_loss: 1.1760e-04\n",
      "Epoch 78/100\n",
      "1792/1792 [==============================] - 0s 162us/step - loss: 1.1079e-04 - val_loss: 1.1021e-04\n",
      "Epoch 79/100\n",
      "1792/1792 [==============================] - 0s 167us/step - loss: 1.0336e-04 - val_loss: 1.0179e-04\n",
      "Epoch 80/100\n",
      "1792/1792 [==============================] - 0s 150us/step - loss: 9.7030e-05 - val_loss: 1.0471e-04\n",
      "Epoch 81/100\n",
      "1792/1792 [==============================] - 0s 159us/step - loss: 1.0101e-04 - val_loss: 1.0718e-04\n",
      "Epoch 82/100\n",
      "1792/1792 [==============================] - 0s 159us/step - loss: 9.8088e-05 - val_loss: 9.2880e-05\n",
      "Epoch 83/100\n",
      "1792/1792 [==============================] - 0s 167us/step - loss: 9.0132e-05 - val_loss: 8.9657e-05\n",
      "Epoch 84/100\n",
      "1792/1792 [==============================] - 0s 157us/step - loss: 8.8800e-05 - val_loss: 7.5831e-05\n",
      "Epoch 85/100\n",
      "1792/1792 [==============================] - 0s 161us/step - loss: 8.0281e-05 - val_loss: 8.0578e-05\n",
      "Epoch 86/100\n",
      "1792/1792 [==============================] - 0s 157us/step - loss: 7.9804e-05 - val_loss: 8.4467e-05\n",
      "Epoch 87/100\n",
      "1792/1792 [==============================] - 0s 167us/step - loss: 7.6920e-05 - val_loss: 7.5035e-05\n",
      "Epoch 88/100\n",
      "1792/1792 [==============================] - 0s 159us/step - loss: 7.9775e-05 - val_loss: 7.1229e-05\n",
      "Epoch 89/100\n",
      "1792/1792 [==============================] - 0s 163us/step - loss: 7.2063e-05 - val_loss: 6.4715e-05\n",
      "Epoch 90/100\n",
      "1792/1792 [==============================] - 0s 158us/step - loss: 6.9259e-05 - val_loss: 7.5803e-05\n",
      "Epoch 91/100\n",
      "1792/1792 [==============================] - 0s 161us/step - loss: 8.1036e-05 - val_loss: 7.0322e-05\n",
      "Epoch 92/100\n",
      "1792/1792 [==============================] - 0s 166us/step - loss: 6.5320e-05 - val_loss: 6.1018e-05\n",
      "Epoch 93/100\n",
      "1792/1792 [==============================] - 0s 172us/step - loss: 6.4552e-05 - val_loss: 6.8134e-05\n",
      "Epoch 94/100\n",
      "1792/1792 [==============================] - 0s 162us/step - loss: 6.0372e-05 - val_loss: 5.9076e-05\n",
      "Epoch 95/100\n",
      "1792/1792 [==============================] - 0s 163us/step - loss: 5.8462e-05 - val_loss: 5.8116e-05\n",
      "Epoch 96/100\n",
      "1792/1792 [==============================] - 0s 169us/step - loss: 5.5221e-05 - val_loss: 5.5668e-05\n",
      "Epoch 97/100\n",
      "1792/1792 [==============================] - 0s 158us/step - loss: 5.1360e-05 - val_loss: 4.9362e-05\n",
      "Epoch 98/100\n",
      "1792/1792 [==============================] - 0s 173us/step - loss: 5.0623e-05 - val_loss: 5.5359e-05\n",
      "Epoch 99/100\n",
      "1792/1792 [==============================] - 0s 158us/step - loss: 4.6810e-05 - val_loss: 5.0233e-05\n",
      "Epoch 100/100\n",
      "1792/1792 [==============================] - 0s 169us/step - loss: 4.8710e-05 - val_loss: 5.0771e-05\n"
     ]
    }
   ],
   "source": [
    "trainer.pre_train_generator(g_epochs=100, g_pre_data_train=[sig_im_train_re, sig_im_train_re_t], g_pre_data_valid=[sig_im_valid_re, sig_im_valid_re_t], lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9256996, 1.0788805]], dtype=float32)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sig_im_test_re[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9242647 1.0786874]]\n"
     ]
    }
   ],
   "source": [
    "print(trainer.predict_pre_generator(sig_im_test_re[:1].reshape(1,1,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.92011595 1.0759159 ]]\n"
     ]
    }
   ],
   "source": [
    "print(trainer.predict_generator(sig_im_test_re[:1].reshape(1,1,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9282605 1.0757881]]\n"
     ]
    }
   ],
   "source": [
    "print(trainer.predict_beta_generator(sig_im_test_re[:1].reshape(1,1,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.253142\n"
     ]
    }
   ],
   "source": [
    "print(trainer.predict_curr_discriminator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.reset_generator(lr=1e-3, epsilon=0.05, beta=5000, binary_reward=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.reflect_pre_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Disc Accuracy: 0.523\n",
      "0: Disc Batch Accuracy: 0.590\n",
      "0, 1: Disc Accuracy: 0.501, Average reward: 0.000\n",
      "1, 1: Disc Accuracy: 0.588, Average reward: 0.000\n",
      "2, 1: Disc Accuracy: 0.515, Average reward: 1.000\n",
      "3, 1: Disc Accuracy: 0.509, Average reward: 0.000\n",
      "4, 1: Disc Accuracy: 0.518, Average reward: 1.000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-22a2d312a5fd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mG:\\My Drive\\Research\\transmitter_impersonation_simple\\SigGAN\\train.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, steps, g_steps, g_weights_path, verbose)\u001b[0m\n\u001b[0;32m    229\u001b[0m                     \u001b[0mstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m                     \u001b[0maction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mact\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 231\u001b[1;33m                     \u001b[0mnext_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_episode_end\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    232\u001b[0m                     \u001b[1;31m#print('Reward: {:.3f}'.format(reward.squeeze()))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m                     \u001b[0mstates\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\My Drive\\Research\\transmitter_impersonation_simple\\SigGAN\\rl.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     75\u001b[0m         \u001b[0mnext_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m         \u001b[0mreward\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mQ\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_sample\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m         \u001b[1;31m#print(\"RRReward \", reward)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\My Drive\\Research\\transmitter_impersonation_simple\\SigGAN\\rl.py\u001b[0m in \u001b[0;36mQ\u001b[1;34m(self, action, n_sample)\u001b[0m\n\u001b[0;32m    102\u001b[0m             \u001b[0mR\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mR_base\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mtau\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 104\u001b[1;33m                 \u001b[0my_tau\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mg_beta\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mact\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    105\u001b[0m                 \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_tau\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcurrent_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtau\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtau\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m                 \u001b[0mR\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_tau\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcurrent_result\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mR\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\My Drive\\Research\\transmitter_impersonation_simple\\SigGAN\\rl.py\u001b[0m in \u001b[0;36mact\u001b[1;34m(self, state)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mact\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0maction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\My Drive\\Research\\transmitter_impersonation_simple\\SigGAN\\models.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, state)\u001b[0m\n\u001b[0;32m    139\u001b[0m             self.beta: self._beta}\n\u001b[0;32m    140\u001b[0m         action = self.sess.run(\n\u001b[1;32m--> 141\u001b[1;33m             [self.sample], feed_dict)\n\u001b[0m\u001b[0;32m    142\u001b[0m         \u001b[1;31m#print(action)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    954\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 956\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    957\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1178\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1180\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1181\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1357\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1359\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1360\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1363\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1364\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1365\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1366\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1367\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1348\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[1;32m-> 1350\u001b[1;33m                                       target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1352\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1441\u001b[0m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[0;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1443\u001b[1;33m                                             run_metadata)\n\u001b[0m\u001b[0;32m   1444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1445\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train(steps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
